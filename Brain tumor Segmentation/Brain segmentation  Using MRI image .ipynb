{"cells":[{"metadata":{"_uuid":"23e77f81-9a0e-4c44-8831-562ff1e34eda","_cell_guid":"3f4447fb-2dbc-4479-b0ac-5ad0f47d4b41","trusted":true},"cell_type":"code","source":"import os\nimport random\n\nfrom collections import OrderedDict\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom matplotlib import pyplot as plt\nfrom matplotlib.backends.backend_agg import FigureCanvasAgg\nfrom tqdm import tqdm\nfrom skimage.exposure import rescale_intensity\nfrom skimage.io import imread, imsave\nfrom skimage.transform import resize, rescale, rotate\nfrom torch.utils.data import Dataset\nfrom torchvision.transforms import Compose\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3848de82-e5ab-44cb-9171-bee421b58c52","_cell_guid":"e1fadc54-4191-42d5-91ea-ad946164d1fa","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ceba14b6-5fc2-4567-a39e-0d2ca2cb8226","_cell_guid":"c31b7342-79e5-4070-a7fc-1077f7a683f5","trusted":true},"cell_type":"code","source":"\nclass UNet(nn.Module):\n\n    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n        super(UNet, self).__init__()\n\n        features = init_features\n        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n\n        self.upconv4 = nn.ConvTranspose2d(\n            features * 16, features * 8, kernel_size=2, stride=2\n        )\n        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n        self.upconv3 = nn.ConvTranspose2d(\n            features * 8, features * 4, kernel_size=2, stride=2\n        )\n        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n        self.upconv2 = nn.ConvTranspose2d(\n            features * 4, features * 2, kernel_size=2, stride=2\n        )\n        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n        self.upconv1 = nn.ConvTranspose2d(\n            features * 2, features, kernel_size=2, stride=2\n        )\n        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n\n        self.conv = nn.Conv2d(\n            in_channels=features, out_channels=out_channels, kernel_size=1\n        )\n\n    def forward(self, x):\n        enc1 = self.encoder1(x)\n        enc2 = self.encoder2(self.pool1(enc1))\n        enc3 = self.encoder3(self.pool2(enc2))\n        enc4 = self.encoder4(self.pool3(enc3))\n\n        bottleneck = self.bottleneck(self.pool4(enc4))\n\n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((dec4, enc4), dim=1)\n        dec4 = self.decoder4(dec4)\n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.decoder3(dec3)\n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.decoder2(dec2)\n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.decoder1(dec1)\n        return torch.sigmoid(self.conv(dec1))\n\n    @staticmethod\n    def _block(in_channels, features, name):\n        return nn.Sequential(\n            OrderedDict(\n                [\n                    (\n                        name + \"conv1\",\n                        nn.Conv2d(\n                            in_channels=in_channels,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n                    (name + \"relu1\", nn.ReLU(inplace=True)),\n                    (\n                        name + \"conv2\",\n                        nn.Conv2d(\n                            in_channels=features,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n                    (name + \"relu2\", nn.ReLU(inplace=True)),\n                ]\n            )\n        )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a79e90cd-b175-42bb-ac69-9e7bbd24f33f","_cell_guid":"d68980de-a81e-42e6-a839-700fb4be3885","trusted":true},"cell_type":"code","source":"class DiceLoss(nn.Module):\n\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n        self.smooth = 1.0\n\n    def forward(self, y_pred, y_true):\n        assert y_pred.size() == y_true.size()\n        y_pred = y_pred[:, 0].contiguous().view(-1)\n        y_true = y_true[:, 0].contiguous().view(-1)\n        intersection = (y_pred * y_true).sum()\n        \n        # DSC(A,B)= 2(Aâˆ©B)/(A+B)  \n        dsc = (2. * intersection + self.smooth) / (\n            y_pred.sum() + y_true.sum() + self.smooth\n        )\n        return 1. - dsc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"984b19a3-8f95-41d2-8d06-23df44730259","_cell_guid":"f14e3de8-692c-4ce8-b8dc-b40ae51d9b0b","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52fda709-630b-48f1-9789-f094113e1160","_cell_guid":"a664aed8-4765-446e-9ca9-8266b63b451b","trusted":true},"cell_type":"code","source":"def gray2rgb(image):\n    w, h = image.shape\n    image += np.abs(np.min(image))\n    image_max = np.abs(np.max(image))\n    if image_max > 0:\n        image /= image_max\n    ret = np.empty((w, h, 3), dtype=np.uint8)\n    ret[:, :, 2] = ret[:, :, 1] = ret[:, :, 0] = image * 255\n    return ret","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64aa523d-bcc8-4a46-b352-d897055c7fe3","_cell_guid":"03a6c575-e6d1-4272-b3fb-a7a91abc9c2b","trusted":true},"cell_type":"code","source":"def outline(image, mask, color):\n    mask = np.round(mask)\n    yy, xx = np.nonzero(mask)\n    for y, x in zip(yy, xx):\n        if 0.0 < np.mean(mask[max(0, y - 1) : y + 2, max(0, x - 1) : x + 2]) < 1.0:\n            image[max(0, y) : y + 1, max(0, x) : x + 1] = color\n    return image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"696eeb79-5d24-42ca-bbdf-9db9adb1b841","_cell_guid":"8b3b54f6-3db7-443d-985e-57f4786bb27a","trusted":true},"cell_type":"code","source":"\ndef log_images(x, y_true, y_pred, channel=1):\n    images = []\n    x_np = x[:, channel].cpu().numpy()\n    y_true_np = y_true[:, 0].cpu().numpy()\n    y_pred_np = y_pred[:, 0].cpu().numpy()\n    for i in range(x_np.shape[0]):\n        image = gray2rgb(np.squeeze(x_np[i]))\n        image = outline(image, y_pred_np[i], color=[255, 0, 0])\n        image = outline(image, y_true_np[i], color=[0, 255, 0])\n        images.append(image)\n    return images","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a50ed8c6-0056-42ea-8e7a-9fe58383d93f","_cell_guid":"796c9912-cbb1-484b-8cac-d6bbb1ca217c","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58935d69-7b4c-4ce3-86c3-74a48d6f7633","_cell_guid":"a1009b87-b6bf-4123-8cce-d9d5ab66c31e","trusted":true},"cell_type":"code","source":"\n\ndef dsc(y_pred, y_true):\n    y_pred = np.round(y_pred).astype(int)\n    y_true = np.round(y_true).astype(int)\n    return np.sum(y_pred[y_true == 1]) * 2.0 / (np.sum(y_pred) + np.sum(y_true))\n\ndef dsc_distribution(volumes):\n    dsc_dict = {}\n    for p in volumes:\n        y_pred = volumes[p][1]\n        y_true = volumes[p][2]\n        dsc_dict[p] = dsc(y_pred, y_true)\n    return dsc_dict\n\n\n\ndef dsc_per_volume(validation_pred, validation_true, patient_slice_index):\n    dsc_list = []\n    num_slices = np.bincount([p[0] for p in patient_slice_index])\n    index = 0\n    for p in range(len(num_slices)):\n        y_pred = np.array(validation_pred[index : index + num_slices[p]])\n        y_true = np.array(validation_true[index : index + num_slices[p]])\n        dsc_list.append(dsc(y_pred, y_true))\n        index += num_slices[p]\n    return dsc_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def perf_measure( y_pred, y_true):\n    y_pred= y_pred.flatten() \n    y_true=y_true.flatten()\n    \n    CM = confusion_matrix(y_true, y_pred)\n\n    TN = CM[0][0]\n    FN = CM[1][0]\n    TP = CM[1][1]\n    FP = CM[0][1]\n    \n    return(TP, FP, TN, FN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef _Jaccard_Similarity_(y_pred, y_true ):\n        y_pred = np.round(y_pred).astype(int)\n        y_true = np.round(y_true).astype(int)\n        \n        TP, FP, TN, FN=perf_measure(y_pred, y_true)\n        \n        return ( TP/ (TP+FP+FN) )\n\n\n\n\n\ndef _statistical_analysis_(validation_pred,  validation_true, patient_slice_index):\n    \n        dsc_list = []\n        num_slices = np.bincount([p[0] for p in patient_slice_index])\n        index = 0\n        for p in range(len(num_slices)):\n            y_pred = np.array(validation_pred[index : index + num_slices[p]])\n            y_true = np.array(validation_true[index : index + num_slices[p]])\n            dsc_list.append(_Jaccard_Similarity_(y_pred, y_true))\n            index += num_slices[p]\n        return dsc_list\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \n    \ndef ppv(y_pred, y_true ):\n        y_pred = np.round(y_pred).astype(int)\n        y_true = np.round(y_true).astype(int)\n        \n        TP, FP, TN, FN=perf_measure(y_pred, y_true)\n        \n        #print(\"y_pred sum = \"  ,np.sum(y_pred)  , \" y_true sum = \"  , np.sum(y_true) )\n        #print(\"TP = \"  , np.sum(y_pred[y_true == 1])  , \"TN  = \"  ,  np.sum(y_pred[y_true == 0]) )\n        \n        #print(\"TP, FP, TN, FN  = \",TP, FP, TN, FN )\n        \n        return TP/(TP+FP)\n              \n        \n\ndef statistical_analysis_ppv(validation_pred,  validation_true, patient_slice_index):\n    \n        dsc_list = []\n        num_slices = np.bincount([p[0] for p in patient_slice_index])\n        index = 0\n        for p in range(len(num_slices)):\n            y_pred = np.array(validation_pred[index : index + num_slices[p]])\n            y_true = np.array(validation_true[index : index + num_slices[p]])\n            dsc_list.append(ppv(y_pred, y_true))\n            index += num_slices[p]\n        return dsc_list\n    \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n              \ndef sensi(y_pred, y_true ):\n        y_pred = np.round(y_pred).astype(int)\n        y_true = np.round(y_true).astype(int)\n        \n        TP, FP, TN, FN=perf_measure(y_pred, y_true)\n        return TP/(TP+FN)\n              \n        \n\ndef statistical_analysis_sensi(validation_pred,  validation_true, patient_slice_index):\n    \n        dsc_list = []\n        num_slices = np.bincount([p[0] for p in patient_slice_index])\n        index = 0\n        for p in range(len(num_slices)):\n            y_pred = np.array(validation_pred[index : index + num_slices[p]])\n            y_true = np.array(validation_true[index : index + num_slices[p]])\n            dsc_list.append(sensi(y_pred, y_true))\n            index += num_slices[p]\n        return dsc_list\n    \n        \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96092ccb-3f93-42be-b4af-2897472dd199","_cell_guid":"0c8e3918-0ad4-47e3-8d01-3d43b9e79398","trusted":true},"cell_type":"code","source":"def postprocess_per_volume( input_list, pred_list, true_list, patient_slice_index, patients):\n    \n    volumes = {}\n    num_slices = np.bincount([p[0] for p in patient_slice_index])\n    index = 0\n    for p in range(len(num_slices)):\n        volume_in = np.array(input_list[index : index + num_slices[p]])\n        volume_pred = np.round(\n            np.array(pred_list[index : index + num_slices[p]])\n        ).astype(int)\n        volume_true = np.array(true_list[index : index + num_slices[p]])\n        volumes[patients[p]] = (volume_in, volume_pred, volume_true)\n        index += num_slices[p]\n    return volumes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11868450-dfe8-4cc5-8d37-bd381d109bb5","_cell_guid":"8b0690f5-7466-46fd-987c-e08b1e6898b0","trusted":true},"cell_type":"code","source":"def log_loss_summary(loss, step, prefix=\"\"):\n    print(\"epoch {} -------------------- {}: {}\".format(step + 1, prefix + \"loss\", np.mean(loss)))\n    \n    \n    \ndef log_scalar_summary(tag, value, step):\n    print(\"epoch {} -------------------- {}: {}\".format(step + 1, tag, value))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64f0ac43-6bda-4898-8593-632dc73fcd4f","_cell_guid":"1c80d53b-e722-45f7-ae82-9db21003bc13","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82c16dd0-1ab9-4c4e-be38-5a93310497a5","_cell_guid":"2a283edd-9e92-4114-ba4f-aeff4eb8c895","trusted":true},"cell_type":"code","source":"\ndef plot_dsc(dsc_dist):\n    y_positions = np.arange(len(dsc_dist))\n    dsc_dist = sorted(dsc_dist.items(), key=lambda x: x[1])\n    values = [x[1] for x in dsc_dist]\n    labels = [x[0] for x in dsc_dist]\n    labels = [\"_\".join(l.split(\"_\")[1:-1]) for l in labels]\n    fig = plt.figure(figsize=(12, 8))\n    canvas = FigureCanvasAgg(fig)\n    plt.barh(y_positions, values, align=\"center\", color=\"skyblue\")\n    plt.yticks(y_positions, labels)\n    plt.xticks(np.arange(0.0, 1.0, 0.1))\n    plt.xlim([0.0, 1.0])\n    plt.gca().axvline(np.mean(values), color=\"tomato\", linewidth=2)\n    plt.gca().axvline(np.median(values), color=\"forestgreen\", linewidth=2)\n    plt.xlabel(\"Dice coefficient\", fontsize=\"x-large\")\n    plt.gca().xaxis.grid(color=\"silver\", alpha=0.5, linestyle=\"--\", linewidth=1)\n    plt.tight_layout()\n    canvas.draw()\n    plt.close()\n    s, (width, height) = canvas.print_to_buffer()\n    return np.fromstring(s, np.uint8).reshape((height, width, 4))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d0baa35-5b57-4bd5-b4a2-fcd83f4faae8","_cell_guid":"de14b4dc-0c11-4a84-846c-35da967b40c6","trusted":true},"cell_type":"code","source":"class HorizontalFlip(object):\n\n    def __init__(self, flip_prob):\n        self.flip_prob = flip_prob\n\n    def __call__(self, sample):\n        image, mask = sample\n\n        if np.random.rand() > self.flip_prob:\n            return image, mask\n\n        image = np.fliplr(image).copy()\n        mask = np.fliplr(mask).copy()\n\n        return image, mask","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"162f71bc-150a-4c01-a506-f7a66230ab8f","_cell_guid":"9c76b3c7-874e-4795-94c4-a36d175b9f3c","trusted":true},"cell_type":"code","source":"class Rotate(object):\n\n    def __init__(self, angle):\n        self.angle = angle\n\n    def __call__(self, sample):\n        image, mask = sample\n\n        angle = np.random.uniform(low=-self.angle, high=self.angle)\n        image = rotate(image, angle, resize=False, preserve_range=True, mode=\"constant\")\n        mask = rotate(\n            mask, angle, resize=False, order=0, preserve_range=True, mode=\"constant\"\n        )\n        return image, mask","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2e80705-eaa3-4951-a919-c4f89db8a417","_cell_guid":"b83ea152-908f-42c7-9b82-29e8345300a5","trusted":true},"cell_type":"code","source":"class Scale(object):\n\n    def __init__(self, scale):\n        self.scale = scale\n\n    def __call__(self, sample):\n        image, mask = sample\n\n        img_size = image.shape[0]\n\n        scale = np.random.uniform(low=1.0 - self.scale, high=1.0 + self.scale)\n\n        image = rescale(\n            image,\n            (scale, scale),\n            multichannel=True,\n            preserve_range=True,\n            mode=\"constant\",\n            anti_aliasing=False,\n        )\n        mask = rescale(\n            mask,\n            (scale, scale),\n            order=0,\n            multichannel=True,\n            preserve_range=True,\n            mode=\"constant\",\n            anti_aliasing=False,\n        )\n\n        if scale < 1.0:\n            diff = (img_size - image.shape[0]) / 2.0\n            padding = ((int(np.floor(diff)), int(np.ceil(diff))),) * 2 + ((0, 0),)\n            image = np.pad(image, padding, mode=\"constant\", constant_values=0)\n            mask = np.pad(mask, padding, mode=\"constant\", constant_values=0)\n        else:\n            x_min = (image.shape[0] - img_size) // 2\n            x_max = x_min + img_size\n            image = image[x_min:x_max, x_min:x_max, ...]\n            mask = mask[x_min:x_max, x_min:x_max, ...]\n\n        return image, mask","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca3c150a-e9f5-4658-b0c6-7aff272450d0","_cell_guid":"ab456dc3-ce45-453f-9e83-f99c59960aae","trusted":true},"cell_type":"code","source":"def transforms(scale=None, angle=None, flip_prob=None):\n    transform_list = []\n\n    if scale is not None:\n        transform_list.append(Scale(scale))\n    if angle is not None:\n        transform_list.append(Rotate(angle))\n    if flip_prob is not None:\n        transform_list.append(HorizontalFlip(flip_prob))\n\n    return Compose(transform_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65f87cf5-0ca3-4625-8749-bca14bea42ee","_cell_guid":"8254a971-7548-459e-b0ad-bccabec246ab","trusted":true},"cell_type":"code","source":"def normalize_volume(volume):\n    p10 = np.percentile(volume, 10)\n    p99 = np.percentile(volume, 99)\n    volume = rescale_intensity(volume, in_range=(p10, p99))\n    m = np.mean(volume, axis=(0, 1, 2))\n    s = np.std(volume, axis=(0, 1, 2))\n    volume = (volume - m) / s\n    return volume","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6c82f86-2600-4fd0-8dd7-f6433be61c99","_cell_guid":"a4f86fb0-713c-48fc-90db-6d498de006cf","trusted":true},"cell_type":"code","source":"def resize_sample(x, size=256):\n    volume, mask = x\n    v_shape = volume.shape\n    out_shape = (v_shape[0], size, size)\n    mask = resize(\n        mask,\n        output_shape=out_shape,\n        order=0,\n        mode=\"constant\",\n        cval=0,\n        anti_aliasing=False,\n    )\n    out_shape = out_shape + (v_shape[3],)\n    volume = resize(\n        volume,\n        output_shape=out_shape,\n        order=2,\n        mode=\"constant\",\n        cval=0,\n        anti_aliasing=False,\n    )\n    return volume, mask","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61ff0e30-67d4-4874-8ee1-8300db336fbc","_cell_guid":"0e16b4a9-86a8-416b-bec4-b8ae2b00b97e","trusted":true},"cell_type":"code","source":"def pad_sample(x):\n    volume, mask = x\n    a = volume.shape[1]\n    b = volume.shape[2]\n    if a == b:\n        return volume, mask\n    diff = (max(a, b) - min(a, b)) / 2.0\n    if a > b:\n        padding = ((0, 0), (0, 0), (int(np.floor(diff)), int(np.ceil(diff))))\n    else:\n        padding = ((0, 0), (int(np.floor(diff)), int(np.ceil(diff))), (0, 0))\n    mask = np.pad(mask, padding, mode=\"constant\", constant_values=0)\n    padding = padding + ((0, 0),)\n    volume = np.pad(volume, padding, mode=\"constant\", constant_values=0)\n    return volume, mask","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c93b8f4a-c944-4cd8-af5d-d5151a682cc9","_cell_guid":"c75e96e9-1b0f-4b00-a7ba-1ef09338fa26","trusted":true},"cell_type":"code","source":"def crop_sample(x):\n    volume, mask = x\n    volume[volume < np.max(volume) * 0.1] = 0\n    z_projection = np.max(np.max(np.max(volume, axis=-1), axis=-1), axis=-1)\n    z_nonzero = np.nonzero(z_projection)\n    z_min = np.min(z_nonzero)\n    z_max = np.max(z_nonzero) + 1\n    y_projection = np.max(np.max(np.max(volume, axis=0), axis=-1), axis=-1)\n    y_nonzero = np.nonzero(y_projection)\n    y_min = np.min(y_nonzero)\n    y_max = np.max(y_nonzero) + 1\n    x_projection = np.max(np.max(np.max(volume, axis=0), axis=0), axis=-1)\n    x_nonzero = np.nonzero(x_projection)\n    x_min = np.min(x_nonzero)\n    x_max = np.max(x_nonzero) + 1\n    return (\n        volume[z_min:z_max, y_min:y_max, x_min:x_max],\n        mask[z_min:z_max, y_min:y_max, x_min:x_max],\n    )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ada84afe-22e2-4596-822b-e5567ca985a0","_cell_guid":"7b9d917e-3f8c-4414-8fea-9c86afaca7db","trusted":true},"cell_type":"code","source":"class BrainSegmentationDataset(Dataset):\n    \"\"\"Brain MRI dataset for FLAIR abnormality segmentation\"\"\"\n\n    in_channels = 3\n    out_channels = 1\n\n    def __init__(\n        self,\n        images_dir,\n        transform=None,\n        image_size=256,\n        subset=\"train\",\n        random_sampling=True,\n        seed=42,\n    ):\n        assert subset in [\"all\", \"train\", \"validation\"]\n\n        # read images\n        volumes = {}\n        masks = {}\n        print(\"reading {} images...\".format(subset))\n        \n        for (dirpath, dirnames, filenames) in os.walk(images_dir):\n            image_slices = []\n            mask_slices = []\n            \n            for filename in sorted(  filter(lambda f: \".tif\" in f, filenames), \n                                     key=lambda x: int(x.split(\".\")[-2].split(\"_\")[4]), ):\n                \n                \n                filepath = os.path.join(dirpath, filename)\n                if \"mask\" in filename:\n                    mask_slices.append(imread(filepath, as_gray=True))\n                else:\n                    image_slices.append(imread(filepath))\n                    \n                    \n            if len(image_slices) > 0:\n                patient_id = dirpath.split(\"/\")[-1]\n                \n                #================\n                #print(\"patient_id = \" , patient_id)\n                #================\n                \n                volumes[patient_id] = np.array(image_slices[1:-1])\n                masks[patient_id] = np.array(mask_slices[1:-1])\n                \n            \n            #print(len(volumes) )\n        self.patients = sorted(volumes)\n\n        # select cases to subset\n        if not subset == \"all\":\n            random.seed(seed)\n            validation_patients = random.sample(self.patients, k=10)\n            \n            if subset == \"validation\":\n                self.patients = validation_patients\n            else:\n                self.patients = sorted( list(set(self.patients).difference(validation_patients)) )\n                \n                \n\n        print(\"preprocessing {} volumes...\".format(subset))\n        # create list of tuples (volume, mask)\n        self.volumes = [(volumes[k], masks[k]) for k in self.patients]\n\n        print(\"cropping {} volumes...\".format(subset))\n        # crop to smallest enclosing volume\n        self.volumes = [crop_sample(v) for v in self.volumes]\n\n        print(\"padding {} volumes...\".format(subset))\n        # pad to square\n        self.volumes = [pad_sample(v) for v in self.volumes]\n\n        print(\"resizing {} volumes...\".format(subset))\n        # resize\n        self.volumes = [resize_sample(v, size=image_size) for v in self.volumes]\n\n        print(\"normalizing {} volumes...\".format(subset))\n        # normalize channel-wise\n        self.volumes = [(normalize_volume(v), m) for v, m in self.volumes]\n\n        \n        \n        # probabilities for sampling slices based on masks\n        self.slice_weights = [m.sum(axis=-1).sum(axis=-1) for v, m in self.volumes]\n        \n        self.slice_weights =[\n            (s + (s.sum() * 0.1 / len(s))) / (s.sum() * 1.1) for s in self.slice_weights\n        ]\n\n        # add channel dimension to masks\n        self.volumes = [(v, m[..., np.newaxis]) for (v, m) in self.volumes]\n\n        print(\"done creating {} dataset\".format(subset))\n\n        \n        # create global index for patient and slice (idx -> (p_idx, s_idx))\n        num_slices = [v.shape[0] for v, m in self.volumes]\n        \n        self.patient_slice_index = list(\n            zip(\n                sum([[i] * num_slices[i] for i in range(len(num_slices))], []),\n                sum([list(range(x)) for x in num_slices], []),\n            )\n        )\n\n        self.random_sampling = random_sampling\n\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.patient_slice_index)\n\n    def __getitem__(self, idx):\n        patient = self.patient_slice_index[idx][0]\n        slice_n = self.patient_slice_index[idx][1]\n\n        if self.random_sampling:\n            patient = np.random.randint(len(self.volumes))\n            slice_n = np.random.choice(\n                range(self.volumes[patient][0].shape[0]), p=self.slice_weights[patient]\n            )\n\n        v, m = self.volumes[patient]\n        image = v[slice_n]\n        mask = m[slice_n]\n\n        if self.transform is not None:\n            image, mask = self.transform((image, mask))\n\n        # fix dimensions (C, H, W)\n        image = image.transpose(2, 0, 1)\n        mask = mask.transpose(2, 0, 1)\n\n        image_tensor = torch.from_numpy(image.astype(np.float32))\n        mask_tensor = torch.from_numpy(mask.astype(np.float32))\n\n        # return tensors\n        return image_tensor, mask_tensor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16de03af-f173-4e82-9f7c-c5a60e9e652d","_cell_guid":"59a4c2ab-bafc-45cd-9647-c62c561336de","trusted":true},"cell_type":"code","source":"\n\ndef datasets(images, image_size, aug_scale, aug_angle):\n    train = BrainSegmentationDataset(\n        images_dir=images,\n        subset=\"train\",\n        image_size=image_size,\n        transform=transforms(scale=aug_scale, angle=aug_angle, flip_prob=0.5),\n    )\n    valid = BrainSegmentationDataset(\n        images_dir=images,\n        subset=\"validation\",\n        image_size=image_size,\n        random_sampling=False,\n    )\n    return train, valid","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1655529-aafd-4e5f-93ef-c72c3864e84c","_cell_guid":"3baad52f-df77-4ef6-92ec-3859f67a44de","trusted":true},"cell_type":"code","source":"\ndef data_loaders(batch_size, workers, image_size, aug_scale, aug_angle):\n    dataset_train, dataset_valid = datasets(\"../input/lgg-mri-segmentation/kaggle_3m\", image_size, aug_scale, aug_angle)\n\n    def worker_init(worker_id):\n        np.random.seed(42 + worker_id)\n        \n    # https://www.journaldev.com/36576/pytorch-dataloader\n\n    loader_train = DataLoader(\n        dataset_train,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=True,\n        num_workers=workers,\n        worker_init_fn=worker_init,\n    )\n    loader_valid = DataLoader(\n        dataset_valid,\n        batch_size=batch_size,\n        drop_last=False,\n        num_workers=workers,\n        worker_init_fn=worker_init,\n    )\n\n    return loader_train, loader_valid","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"474cd2f7-61e8-4e2a-90f9-ec7d1e4f557a","_cell_guid":"e44488d0-176a-4b28-9e38-3beccc6b1a3e","trusted":true},"cell_type":"code","source":"batch_size = 20\nepochs = 60\nlr = 0.00006\nworkers = 2\nweights = \"./\"\nimage_size = 224\naug_scale = 0.05\naug_angle = 15","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e63376c-fcc7-49f7-9174-f09a4232a336","_cell_guid":"d41b803a-9c6e-4b2b-bb96-74a0a2faabf5","trusted":true},"cell_type":"code","source":"\ndef Model_Run():\n    device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n    \n    loader_train, loader_valid = data_loaders(batch_size, workers, image_size, aug_scale, aug_angle)\n    loaders = {\"train\": loader_train, \"valid\": loader_valid}\n    \n    print(\"Length of loader_train, loader_valid \" ,  len(loader_train), len(loader_valid) )\n    print(\"BrainSegmentationDataset.in_channels  and ouput channel \" , BrainSegmentationDataset.in_channels  , BrainSegmentationDataset.out_channels)\n    \n    unet = UNet(in_channels=BrainSegmentationDataset.in_channels, out_channels=BrainSegmentationDataset.out_channels)\n    unet.to(device)\n    \n    dsc_loss = DiceLoss()\n    best_validation_dsc = 0.0\n    \n    best_validation_dsc_mean = 0.0\n    best_validation_dsc_median = 0.0\n    \n    best_Jaccard_Similarity_mean = 0.0\n    best_Jaccard_Similarity_median=0.0\n    \n    \n    optimizer = optim.Adam(unet.parameters(), lr=lr)\n    \n    loss_train = []\n    loss_valid = []\n    \n    step = 0\n    \n    for epoch in range(epochs):\n        for phase in [\"train\", \"valid\"]:\n            if phase == \"train\":\n                unet.train()\n            else:\n                unet.eval()\n    \n            validation_pred = []\n            validation_true = []\n            \n            #print(\"First Loader phase \", phase)\n            cnt=0\n            val_cnt=0\n    \n            for i, data in enumerate(loaders[phase]):\n                \n                cnt+=1\n                \n                \n                if phase == \"train\":\n                    step += 1\n    \n                x, y_true = data\n                x, y_true = x.to(device), y_true.to(device)\n    \n                optimizer.zero_grad()\n    \n                with torch.set_grad_enabled(phase == \"train\"):\n                    y_pred = unet(x)\n    \n                    loss = dsc_loss(y_pred, y_true)\n        \n                    #print(\"Loss \"  , loss)\n    \n                    if phase == \"valid\":\n                        val_cnt+=1\n                        loss_valid.append(loss.item())\n                \n                        y_pred_np = y_pred.detach().cpu().numpy()\n                        validation_pred.extend([y_pred_np[s] for s in range(y_pred_np.shape[0])])\n                        \n                        y_true_np = y_true.detach().cpu().numpy()\n                        validation_true.extend( [y_true_np[s] for s in range(y_true_np.shape[0])])\n                        \n                        \n                    if phase == \"train\":\n                        loss_train.append(loss.item())\n                        loss.backward()\n                        optimizer.step()\n                        \n            #print(\"Count First phase =  \",phase, \"cnt= \",  cnt  , \" val_cnt =\" ,  val_cnt )\n    \n            if phase == \"train\":\n                log_loss_summary(loss_train, epoch)\n                loss_train = []\n\n            if phase == \"valid\":\n                log_loss_summary(loss_valid, epoch, prefix=\"val_\")\n                mean_dsc= np.mean(\n                    dsc_per_volume(\n                        validation_pred,\n                        validation_true,\n                        loader_valid.dataset.patient_slice_index,\n                    ))\n                    \n                   \n                median_dsc=np.median( \n                dsc_per_volume(\n                    validation_pred,\n                    validation_true,\n                    loader_valid.dataset.patient_slice_index,\n                ))\n                \n                std_dsc=np.std( \n                dsc_per_volume(\n                    validation_pred,\n                    validation_true,\n                    loader_valid.dataset.patient_slice_index,\n                ))\n\n                    \n                    \n                Jaccard_Similarity_mean = np.mean(_statistical_analysis_( \n                    validation_pred,validation_true,loader_valid.dataset.patient_slice_index,  ))\n\n                Jaccard_Similarity_median=np.median( _statistical_analysis_( \n                    validation_pred,validation_true,loader_valid.dataset.patient_slice_index,  ))\n                \n                Jaccard_Similarity_std=np.std( _statistical_analysis_( \n                    validation_pred,validation_true,loader_valid.dataset.patient_slice_index,  ))\n                \n                ppv =np.mean( statistical_analysis_ppv( \n                    validation_pred,validation_true,loader_valid.dataset.patient_slice_index,  ))\n\n                sensitivity =np.mean( statistical_analysis_sensi( \n                    validation_pred,validation_true,loader_valid.dataset.patient_slice_index,  ))\n                \n                \n                \n\n                log_scalar_summary(\"val_mean_dsc \", mean_dsc, epoch)\n                log_scalar_summary(\"val_median_dsc \", median_dsc, epoch)\n                log_scalar_summary(\"val_Std_dsc \", std_dsc, epoch)\n                \n                log_scalar_summary(\"PPV \", ppv, epoch)\n                log_scalar_summary(\"Sensitivity \",sensitivity, epoch)\n\n                log_scalar_summary(\"Jaccard_mean_Similarity \", Jaccard_Similarity_mean, epoch)\n                log_scalar_summary(\"Jaccard_median_Similarity \", Jaccard_Similarity_median, epoch)\n                log_scalar_summary(\"Jaccard_median_Std \",  Jaccard_Similarity_std, epoch)\n                \n\n                if mean_dsc > best_validation_dsc_mean:\n                        best_validation_dsc_mean = mean_dsc\n                        torch.save(unet.state_dict(), os.path.join(weights, \"unet.pt\"))\n\n                if median_dsc > best_validation_dsc_median:\n                        best_validation_dsc_median= median_dsc\n\n\n                if  Jaccard_Similarity_mean > best_Jaccard_Similarity_mean:\n                                best_Jaccard_Similarity_mean = Jaccard_Similarity_mean \n\n                if  Jaccard_Similarity_median > best_Jaccard_Similarity_median:\n                                best_Jaccard_Similarity_median = Jaccard_Similarity_median\n\n\n                loss_valid = []\n                \n    \n    print(\"\\nBest_Jaccard_Similarity_mean: {:4f}\\n\".format(best_Jaccard_Similarity_mean))\n    print(\"\\nJaccard_Similarity_median: {:4f}\\n\".format(Jaccard_Similarity_median))\n    print(\"\\nBest validation mean DSC: {:4f}\\n\".format(best_validation_dsc_mean))\n    print(\"\\nBest validation mean DSC: {:4f}\\n\".format(best_validation_dsc_median))\n    \n    state_dict = torch.load(os.path.join(weights, \"unet.pt\"))\n    unet.load_state_dict(state_dict)\n    unet.eval()\n    \n    input_list = []\n    pred_list = []\n    true_list = []\n    \n    print(\"loader_valid \" , len(loader_valid) )\n    for i, data in enumerate(loader_valid):\n        #print(\"eveluate \"  , i , data)\n        x, y_true = data\n        x, y_true = x.to(device), y_true.to(device)\n        with torch.set_grad_enabled(False):\n            y_pred = unet(x)\n            y_pred_np = y_pred.detach().cpu().numpy()\n            pred_list.extend([y_pred_np[s] for s in range(y_pred_np.shape[0])])\n            y_true_np = y_true.detach().cpu().numpy()\n            true_list.extend([y_true_np[s] for s in range(y_true_np.shape[0])])\n            x_np = x.detach().cpu().numpy()\n            input_list.extend([x_np[s] for s in range(x_np.shape[0])])\n            \n    volumes = postprocess_per_volume(\n        input_list,\n        pred_list,\n        true_list,\n        loader_valid.dataset.patient_slice_index,\n        loader_valid.dataset.patients,\n    )\n    \n    dsc_dist = dsc_distribution(volumes)\n\n    dsc_dist_plot = plot_dsc(dsc_dist)\n    imsave(\"./dsc.png\", dsc_dist_plot)\n\n    import matplotlib.pyplot as plt\n    \n    for p in volumes:\n        x = volumes[p][0]\n        y_pred = volumes[p][1]\n        y_true = volumes[p][2]\n        for s in range(x.shape[0]):\n            image = gray2rgb(x[s, 1])  # channel 1 is for FLAIR\n            image = outline(image, y_pred[s, 0], color=[255, 0, 0])\n            image = outline(image, y_true[s, 0], color=[0, 255, 0])\n            filename = \"{}-{}.png\".format(p, str(s).zfill(2))\n            \n            #plt.imshow(filename)\n            filepath = os.path.join(\"./\", filename)\n            imsave(filepath, image)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96e11451-a1d0-46c5-be9d-142d2c5c84b4","_cell_guid":"1eebb69e-15b0-42aa-bbf1-ac19927d5eb1","trusted":true},"cell_type":"code","source":"Model_Run()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6e7e5fc-3016-4aa6-82c0-11d6ccfccb4e","_cell_guid":"6d051cfb-2982-4adc-8db1-0af631474d96","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}