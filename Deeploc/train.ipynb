{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train the model\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load utils.py\n",
    "import json\n",
    "import logging\n",
    "#It can help you develop a better understanding of the flow of a program and \n",
    "#discover scenarios that you might not even have thought of while developing.\n",
    "import os\n",
    "import shutil\n",
    "#The shutil module offers a number of high-level operations on files and collections of files.\n",
    "#In particular, functions are provided which support file copying and removal\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class Params():\n",
    "    \"\"\"Class that loads hyperparameters from a json file.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    params = Params(json_path)\n",
    "    print(params.learning_rate)\n",
    "    params.learning_rate = 0.5  # change the value of learning_rate in params\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, json_path):\n",
    "        with open(json_path) as f:\n",
    "            params = json.load(f)\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    def save(self, json_path):\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n",
    "\n",
    "    def update(self, json_path):\n",
    "        \"\"\"Loads parameters from json file\"\"\"\n",
    "        with open(json_path) as f:\n",
    "            params = json.load(f)\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    @property\n",
    "    def dict(self):\n",
    "        \"\"\"Gives dict-like access to Params instance by `params.dict['learning_rate']\"\"\"\n",
    "        return self.__dict__\n",
    "\n",
    "\n",
    "class RunningAverage():\n",
    "    \"\"\"A simple class that maintains the running average of a quantity\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    loss_avg = RunningAverage()\n",
    "    loss_avg.update(2)\n",
    "    loss_avg.update(4)\n",
    "    loss_avg() = 3\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.total += val\n",
    "        self.steps += 1\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.total / float(self.steps)\n",
    "\n",
    "\n",
    "def set_logger(log_path):\n",
    "    \"\"\"Set the logger to log info in terminal and file `log_path`.\n",
    "\n",
    "    In general, it is useful to have a logger so that every output to the terminal is saved\n",
    "    in a permanent file. Here we save it to `model_dir/train.log`.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    logging.info(\"Starting training...\")\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "        log_path: (string) where to log\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    if not logger.handlers:\n",
    "        # Logging to a file\n",
    "        file_handler = logging.FileHandler(log_path)\n",
    "        file_handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "        # Logging to console\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        stream_handler.setFormatter(logging.Formatter('%(message)s'))\n",
    "        logger.addHandler(stream_handler)\n",
    "\n",
    "\n",
    "def save_dict_to_json(d, json_path):\n",
    "    \"\"\"Saves dict of floats in json file\n",
    "\n",
    "    Args:\n",
    "        d: (dict) of float-castable values (np.float, int, float, etc.)\n",
    "        json_path: (string) path to json file\n",
    "    \"\"\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        # We need to convert the values to float for json (it doesn't accept np.array, np.float, )\n",
    "        d = {k: float(v) for k, v in d.items()}\n",
    "        json.dump(d, f, indent=4)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint):\n",
    "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
    "    checkpoint + 'best.pth.tar'\n",
    "\n",
    "    Args:\n",
    "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
    "        is_best: (bool) True if it is the best model seen till now\n",
    "        checkpoint: (string) folder where parameters are to be saved\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(checkpoint, 'last.pth')\n",
    "    if not os.path.exists(checkpoint):\n",
    "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
    "        os.mkdir(checkpoint)\n",
    "    else:\n",
    "        print(\"Checkpoint Directory exists! \")\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth'))\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer=None):\n",
    "    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
    "    optimizer assuming it is present in checkpoint.\n",
    "\n",
    "    Args:\n",
    "        checkpoint: (string) filename which needs to be loaded\n",
    "        model: (torch.nn.Module) model for which the parameters are loaded\n",
    "        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
    "    \"\"\"\n",
    "    if not os.path.exists(checkpoint):\n",
    "        raise (\"File doesn't exist {}\".format(checkpoint))\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optim_dict'])\n",
    "\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load File :  <_io.TextIOWrapper name='experiments/base_model\\\\params.json' mode='r' encoding='cp1252'>\n",
      "params :  {'learning_rate': 0.001, 'batch_size': 5, 'num_epochs': 5, 'dropout': 0.5, 'number_of_tags': 50, 'bidirectional': 1, 'n_layers': 2, 'lstm_hidden_dim': 40, 'embedding_dim': 20, 'save_summary_steps': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load File :  <_io.TextIOWrapper name='data\\\\dataset_params.json' mode='r' encoding='cp1252'>\n",
      "params :  {'train_size': 304, 'dev_size': 65, 'test_size': 66, 'vocab_size': 21, 'number_of_classes': 10, 'pad_word': '<pad>'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- done.\n",
      "Starting evaluation\n",
      "- Eval metrics : accuracy: 0.262 ; loss: 2.198\n"
     ]
    }
   ],
   "source": [
    "# %load evaluate.py\n",
    "\"\"\"Evaluates the model\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import  easydict \n",
    "from easydict import EasyDict \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "import model.net as net\n",
    "from model.data_loader import DataLoader\n",
    "\n",
    "''' \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir', default='data', help=\"Directory containing the dataset\")\n",
    "parser.add_argument('--model_dir', default='experiments/base_model', help=\"Directory containing params.json\")\n",
    "parser.add_argument('--restore_file', default='best', help=\"name of the file in --model_dir \\\n",
    "                     containing weights to load\")\n",
    "'''\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate(model, loss_fn, data_iterator, metrics, params, num_steps):\n",
    "    \"\"\"Evaluate the model on `num_steps` batches.\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        data_iterator: (generator) a generator that generates batches of data and labels\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # summary for current eval loop\n",
    "    summ = []\n",
    "\n",
    "    # compute metrics over the dataset\n",
    "    for _ in range(num_steps):\n",
    "        # fetch the next evaluation batch\n",
    "        data_batch, labels_batch = next(data_iterator)\n",
    "        \n",
    "        # compute model output\n",
    "        output_batch = model(data_batch)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "        output_batch = output_batch.data.cpu().numpy()\n",
    "        labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "        # compute all metrics on this batch\n",
    "        summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                         for metric in metrics}\n",
    "        summary_batch['loss'] = loss.item()#loss.data[0]\n",
    "        summ.append(summary_batch)\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    logging.info(\"- Eval metrics : \" + metrics_string)\n",
    "    return metrics_mean\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "        Evaluate the model on the test set.\n",
    "    \"\"\"\n",
    "    # Load the parameters\n",
    "    #args = parser.parse_args()\n",
    "    \n",
    "    args = easydict.EasyDict({\n",
    "    \"restore_file\": 'best',\n",
    "    \"model_dir\": 'experiments/base_model',\n",
    "    \"data_dir\": \"data\"\n",
    "    })\n",
    "    \n",
    "    json_path = os.path.join(args.model_dir, 'params.json')\n",
    "    assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "    params = utils.Params(json_path)\n",
    "    \n",
    "    #print(json_path, params)\n",
    "\n",
    "    # use GPU if available\n",
    "    params.cuda = torch.cuda.is_available()     # use GPU is available\n",
    "\n",
    "    # Set the random seed for reproducible experiments\n",
    "    torch.manual_seed(230)\n",
    "    if params.cuda: torch.cuda.manual_seed(230)\n",
    "        \n",
    "    # Get the logger\n",
    "    utils.set_logger(os.path.join(args.model_dir, 'evaluate.log'))\n",
    "\n",
    "    # Create the input data pipeline\n",
    "    logging.info(\"Creating the dataset...\")\n",
    "\n",
    "    # load data\n",
    "    data_loader = DataLoader(args.data_dir, params)\n",
    "    data = data_loader.load_data(['test'], args.data_dir)\n",
    "    test_data = data['test']\n",
    "\n",
    "    # specify the test set size\n",
    "    params.test_size = test_data['size']\n",
    "    test_data_iterator = data_loader.data_iterator(test_data, params)\n",
    "\n",
    "    logging.info(\"- done.\")\n",
    "\n",
    "    # Define the model\n",
    "    model = net.Net(params).cuda() if params.cuda else net.Net(params)\n",
    "    \n",
    "    loss_fn = net.loss_fn\n",
    "    metrics = net.metrics\n",
    "    \n",
    "    logging.info(\"Starting evaluation\")\n",
    "\n",
    "    # Reload weights from the saved file\n",
    "    utils.load_checkpoint(os.path.join(args.model_dir, args.restore_file + '.pth'), model)\n",
    "\n",
    "    # Evaluate\n",
    "    num_steps = (params.test_size + 1) // params.batch_size\n",
    "    test_metrics = evaluate(model, loss_fn, test_data_iterator, metrics, params, num_steps)\n",
    "    save_path = os.path.join(args.model_dir, \"metrics_test_{}.json\".format(args.restore_file))\n",
    "    utils.save_dict_to_json(test_metrics, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.net as net\n",
    "from model.data_loader import DataLoader\n",
    "from evaluate import evaluate\n",
    "\n",
    "import  easydict \n",
    "from easydict import EasyDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, data_iterator, metrics, params, num_steps):\n",
    "    \"\"\"Train the model on `num_steps` batches\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        optimizer: (torch.optim) optimizer for parameters of model\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        data_iterator: (generator) a generator that generates batches of data and labels\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = utils.RunningAverage()\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    t = trange(num_steps) \n",
    "    for i in t:\n",
    "        # fetch the next training batch\n",
    "        train_batch, labels_batch = next(data_iterator)\n",
    "\n",
    "        # compute model output and loss\n",
    "        output_batch = model(train_batch)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate summaries only once in a while\n",
    "        if i % params.save_summary_steps == 0:\n",
    "            # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "            output_batch = output_batch.data.cpu().numpy()\n",
    "            labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "            # compute all metrics on this batch\n",
    "            summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n",
    "                             for metric in metrics}\n",
    "            summary_batch['loss'] = loss.item() #loss.data[0]\n",
    "            summ.append(summary_batch)\n",
    "\n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())#loss.data[0])\n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    logging.info(\"- Train metrics: \" + metrics_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_data, val_data, optimizer, loss_fn, metrics, params, model_dir, restore_file=None):\n",
    "    \"\"\"Train the model and evaluate every epoch.\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        train_data: (dict) training data with keys 'data' and 'labels'\n",
    "        val_data: (dict) validaion data with keys 'data' and 'labels'\n",
    "        optimizer: (torch.optim) optimizer for parameters of model\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        model_dir: (string) directory containing config, weights and log\n",
    "        restore_file: (string) optional- name of file to restore from (without its extension .pth.tar)\n",
    "    \"\"\"\n",
    "    # reload weights from restore_file if specified\n",
    "    if restore_file is not None:\n",
    "        restore_path = os.path.join(args.model_dir, args.restore_file + '.pth')\n",
    "        logging.info(\"Restoring parameters from {}\".format(restore_path))\n",
    "        utils.load_checkpoint(restore_path, model, optimizer)\n",
    "        \n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(params.num_epochs):\n",
    "        # Run one epoch\n",
    "        logging.info(\"Epoch {}/{}\".format(epoch + 1, params.num_epochs))\n",
    "\n",
    "        # compute number of batches in one epoch (one full pass over the training set)\n",
    "        num_steps = (params.train_size + 1) // params.batch_size\n",
    "        train_data_iterator = data_loader.data_iterator(train_data, params, shuffle=True)\n",
    "        train(model, optimizer, loss_fn, train_data_iterator, metrics, params, num_steps)\n",
    "            \n",
    "        # Evaluate for one epoch on validation set\n",
    "        num_steps = (params.val_size + 1) // params.batch_size\n",
    "        val_data_iterator = data_loader.data_iterator(val_data, params, shuffle=False)\n",
    "        val_metrics = evaluate(model, loss_fn, val_data_iterator, metrics, params, num_steps)\n",
    "        \n",
    "        val_acc = val_metrics['accuracy']\n",
    "        is_best = val_acc >= best_val_acc\n",
    "\n",
    "        # Save weights\n",
    "        utils.save_checkpoint({'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optim_dict' : optimizer.state_dict()}, \n",
    "                               is_best=is_best,\n",
    "                               checkpoint=model_dir)\n",
    "            \n",
    "        # If best_eval, best_save_path        \n",
    "        if is_best:\n",
    "            logging.info(\"- Found new best accuracy\")\n",
    "            best_val_acc = val_acc\n",
    "            \n",
    "            # Save best val metrics in a json file in the model directory\n",
    "            best_json_path = os.path.join(model_dir, \"metrics_val_best_weights.json\")\n",
    "            utils.save_dict_to_json(val_metrics, best_json_path)\n",
    "\n",
    "        # Save latest val metrics in a json file in the model directory\n",
    "        last_json_path = os.path.join(model_dir, \"metrics_val_last_weights.json\")\n",
    "        utils.save_dict_to_json(val_metrics, last_json_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load File :  <_io.TextIOWrapper name='experiments/base_model\\\\params.json' mode='r' encoding='cp1252'>\n",
      "params :  {'learning_rate': 0.001, 'batch_size': 5, 'num_epochs': 5, 'dropout': 0.5, 'number_of_tags': 50, 'bidirectional': 1, 'n_layers': 2, 'lstm_hidden_dim': 40, 'embedding_dim': 20, 'save_summary_steps': 100}\n",
      "Train params :  <utils.Params object at 0x0000020FDD5A5988>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load File :  <_io.TextIOWrapper name='data\\\\dataset_params.json' mode='r' encoding='cp1252'>\n",
      "params :  {'train_size': 304, 'dev_size': 65, 'test_size': 66, 'vocab_size': 21, 'number_of_classes': 10, 'pad_word': '<pad>'}\n",
      "data_loader  <model.data_loader.DataLoader object at 0x0000020FEF09FA08>\n",
      "tarin size , val size  :  304 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- done.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load the parameters from json file\n",
    "    #args = parser.parse_args()\n",
    "    \n",
    "    ''' \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', default='data', help=\"Directory containing the dataset\")\n",
    "    parser.add_argument('--model_dir', default='experiments/base_model', help=\"Directory containing params.json\")\n",
    "    parser.add_argument('--restore_file', default=None,\n",
    "                        help=\"Optional, name of the file in --model_dir containing weights to reload before \\\n",
    "                        training\")  # 'best' or 'train'\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    args = easydict.EasyDict({\n",
    "    \"model_dir\": \"experiments/base_model\",\n",
    "    \"restore_file\": None,\n",
    "    \"data_dir\": \"data\"\n",
    "    })\n",
    "\n",
    "    \n",
    "    json_path = os.path.join(args.model_dir, 'params.json')\n",
    "    assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "    params = utils.Params(json_path)  #Convert JSON data to a Python dictionary\n",
    "    \n",
    "    print(\"Train params : \", params)\n",
    "\n",
    "    # use GPU if available\n",
    "    params.cuda = torch.cuda.is_available()\n",
    "    \n",
    "    # Set the random seed for reproducible experiments\n",
    "    torch.manual_seed(230)\n",
    "    if params.cuda: torch.cuda.manual_seed(230)\n",
    "        \n",
    "    # Set the logger\n",
    "    utils.set_logger(os.path.join(args.model_dir, 'train.log'))\n",
    "    \n",
    "\n",
    "    # Create the input data pipeline\n",
    "    logging.info(\"Loading the datasets...\")\n",
    "    \n",
    "    # load data\n",
    "    data_loader = DataLoader(args.data_dir, params)\n",
    "    print(\"data_loader \", data_loader)\n",
    "    data = data_loader.load_data( ['train', 'val'], args.data_dir)\n",
    "    \n",
    "    #print(\"Data \", data)\n",
    "    train_data = data['train']\n",
    "    val_data = data['val']\n",
    "    \n",
    "    print(\"tarin size , val size  : \", train_data['size'], val_data['size'])\n",
    "\n",
    "    # specify the train and val dataset sizes\n",
    "    params.train_size = train_data['size']\n",
    "    params.val_size = val_data['size']\n",
    "\n",
    "    logging.info(\"- done.\")\n",
    "    \n",
    "    \n",
    "    # Define the model and optimizer\n",
    "    model = net.Net(params).cuda() if params.cuda else net.Net(params)\n",
    "    torch.save(model, 'model_for_visulization.pth')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    # fetch loss function and metrics\n",
    "    loss_fn = net.loss_fn\n",
    "    metrics = net.metrics\n",
    "\n",
    "    # Train the model\n",
    "    logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
    "    train_and_evaluate(model, train_data, val_data, optimizer, loss_fn, metrics, params, args.model_dir,\n",
    "                       args.restore_file)\n",
    "                       \n",
    "                       '''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
